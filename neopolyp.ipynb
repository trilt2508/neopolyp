{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\n\nimport torch.utils.data as data\nimport os\nimport random\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport math\nimport random\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:48.411755Z","iopub.execute_input":"2022-07-20T16:08:48.412837Z","iopub.status.idle":"2022-07-20T16:08:49.120780Z","shell.execute_reply.started":"2022-07-20T16:08:48.412628Z","shell.execute_reply":"2022-07-20T16:08:49.119425Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(image, mask, flip=False, scale=None, crop=None):\n    if flip:\n        if random.random() < 0.5:\n            image = image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n            mask = mask.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n            \n    if scale:\n        w, h = image.size\n        rand_log_scale = math.log(\n            scale[0], 2) + random.random() * (math.log(scale[1], 2) - math.log(scale[0], 2))\n        random_scale = math.pow(2, rand_log_scale)\n        new_size = (int(round(w * random_scale)), int(round(h * random_scale)))\n        image = image.resize(new_size, Image.Resampling.LANCZOS)\n        mask = mask.resize(new_size, Image.Resampling.NEAREST)\n\n    data_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    image = data_transforms(image)\n    mask = TF.to_tensor(mask).round().long()\n\n    # to 1D mask HACK\n    mask = (mask[0] + mask[1] * 2).clamp(max=2)\n    \n    if crop:\n        h, w = image.shape[1], image.shape[2]\n        pad_tb = max(0, crop[0] - h)\n        pad_lr = max(0, crop[1] - w)\n        image = torch.nn.ZeroPad2d((0, pad_lr, 0, pad_tb))(image)\n        mask = torch.nn.ConstantPad2d((0, pad_lr, 0, pad_tb), 255)(mask)\n\n        h, w = image.shape[1], image.shape[2]\n        i = random.randint(0, h - crop[0])\n        j = random.randint(0, w - crop[1])\n        image = image[:, i:i + crop[0], j:j + crop[1]]\n        mask = mask[i:i + crop[0], j:j + crop[1]]\n\n    return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:49.130604Z","iopub.execute_input":"2022-07-20T16:08:49.131380Z","iopub.status.idle":"2022-07-20T16:08:49.147779Z","shell.execute_reply.started":"2022-07-20T16:08:49.131321Z","shell.execute_reply":"2022-07-20T16:08:49.146267Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"_DATA_FORMAT_MAP = {\n    'image': 'jpeg',\n    'label': 'jpeg',\n}\n\n_DATA_FOLDER_SUFFIX = {\n    'image': '',\n    'label': '_gt'\n}\n\n\nclass NeoPolyp(data.Dataset):\n    def __init__(self, root, train=True, transform=None, target_transform=None, crop_size=None):\n        self.root = root\n        self.transform = transform\n        self.target_transform = target_transform\n        self.train = train\n        self.crop_size = crop_size\n\n        dataset_split = 'train' if self.train else 'val'\n        self.images = self._get_files('image', dataset_split)\n        self.masks = self._get_files('label', dataset_split)\n\n    def __getitem__(self, index):\n        _img = Image.open(self.images[index]).convert('RGB')\n        _target = Image.open(self.masks[index])\n\n        _img, _target = preprocess(_img, _target,\n                                   flip=True if self.train else False,\n                                   scale=(0.66, 1.5) if self.train else None,\n                                   crop=self.crop_size if self.train else (1024, 1280))\n\n        if self.transform is not None:\n            _img = self.transform(_img)\n\n        if self.target_transform is not None:\n            _target = self.target_transform(_target)\n\n        return _img, _target\n\n    def _get_files(self, data, dataset_split):\n        folder_name = dataset_split + _DATA_FOLDER_SUFFIX[data]\n        pattern = '*.{}'.format(_DATA_FORMAT_MAP[data])\n        search_files = os.path.join(\n            self.root, folder_name, folder_name, pattern)\n        filenames = glob.glob(search_files)\n        return sorted(filenames)\n\n    def __len__(self):\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:49.149770Z","iopub.execute_input":"2022-07-20T16:08:49.150550Z","iopub.status.idle":"2022-07-20T16:08:49.168449Z","shell.execute_reply.started":"2022-07-20T16:08:49.150504Z","shell.execute_reply":"2022-07-20T16:08:49.167277Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data = NeoPolyp(\"/kaggle/input/bkai-neopolyp/bkai-igh-neopolyp\", train=True, crop_size=(640, 800))\nval_data = NeoPolyp(\"/kaggle/input/bkai-neopolyp/bkai-igh-neopolyp\", train=False, crop_size=(1024, 1280))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:49.172891Z","iopub.execute_input":"2022-07-20T16:08:49.173683Z","iopub.status.idle":"2022-07-20T16:08:49.204136Z","shell.execute_reply.started":"2022-07-20T16:08:49.173615Z","shell.execute_reply":"2022-07-20T16:08:49.202926Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:49.206992Z","iopub.execute_input":"2022-07-20T16:08:49.207839Z","iopub.status.idle":"2022-07-20T16:08:49.215068Z","shell.execute_reply.started":"2022-07-20T16:08:49.207796Z","shell.execute_reply":"2022-07-20T16:08:49.213849Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Model (DeeplabV3)","metadata":{}},{"cell_type":"code","source":"from torchvision.models.segmentation import deeplabv3_resnet50\nmodel = deeplabv3_resnet50(num_classes=3).cuda()\nmodel.train();","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:49.216646Z","iopub.execute_input":"2022-07-20T16:08:49.218898Z","iopub.status.idle":"2022-07-20T16:08:51.712423Z","shell.execute_reply.started":"2022-07-20T16:08:49.218856Z","shell.execute_reply":"2022-07-20T16:08:51.711002Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=255)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:51.714321Z","iopub.execute_input":"2022-07-20T16:08:51.715888Z","iopub.status.idle":"2022-07-20T16:08:51.725162Z","shell.execute_reply.started":"2022-07-20T16:08:51.715824Z","shell.execute_reply":"2022-07-20T16:08:51.723761Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Training and evaluation","metadata":{}},{"cell_type":"code","source":"from torchmetrics import Dice, JaccardIndex\n\nkwargs = {\n    \"num_classes\": 3, \n    \"ignore_index\": 0\n}\ntrain_dice, eval_dice, train_iou, eval_iou = Dice(**kwargs).cuda(), Dice(**kwargs).cuda(), JaccardIndex(**kwargs).cuda(), JaccardIndex(**kwargs).cuda()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:51.727285Z","iopub.execute_input":"2022-07-20T16:08:51.728481Z","iopub.status.idle":"2022-07-20T16:08:51.969081Z","shell.execute_reply.started":"2022-07-20T16:08:51.728437Z","shell.execute_reply":"2022-07-20T16:08:51.967775Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def evaluate(model):\n    model.eval()\n    with torch.no_grad():\n        for i, (inputs, target) in enumerate(val_loader):\n            inputs, target = inputs.cuda(), target.cuda()\n            outputs = model(inputs)['out']\n\n            eval_pred = outputs.argmax(dim=1)\n            target = torch.where(target > 2, 0, target)\n            eval_dice_metric, eval_iou_metric = eval_dice(eval_pred, target), eval_iou(eval_pred, target)\n        eval_dice_metric, eval_iou_metric = eval_dice.compute(), eval_iou.compute()\n        print(f\"Val metric on epoch {epoch}: {eval_dice_metric.item():.4f}, {eval_iou_metric.item():.4f}\")\n        eval_dice.reset(), eval_iou.reset()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T16:08:51.971359Z","iopub.execute_input":"2022-07-20T16:08:51.971891Z","iopub.status.idle":"2022-07-20T16:08:51.981854Z","shell.execute_reply.started":"2022-07-20T16:08:51.971845Z","shell.execute_reply":"2022-07-20T16:08:51.980466Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"start_epoch = 0\nepochs = 10\n\nfor epoch in range(start_epoch, epochs):\n    model.train()\n    for i, (inputs, target) in enumerate(train_loader):\n        inputs, target = inputs.cuda(), target.cuda()\n        outputs = model(inputs)['out']\n        loss = criterion(outputs, target)\n#         if np.isnan(loss.item()) or np.isinf(loss.item()):\n#             pdb.set_trace()\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        train_pred = outputs.argmax(dim=1)\n        target = torch.where(target > 2, 0, target)\n        train_dice_metric, train_iou_metric = train_dice(train_pred, target), train_iou(train_pred, target)\n        if (i+1) % 20 == 0:\n            print('epoch: {0}\\t'\n                  'iter: {1}/{2}\\t'\n                  'loss: {3:.4f})'.format(epoch, i+1, len(train_loader), loss.item()))\n            print(f\"Train metrics on batch {i+1}: {train_dice_metric.item():.4f}, {train_iou_metric.item():.4f}\")\n            \n    train_dice_metric, train_iou_metric = train_dice.compute(), train_iou.compute()\n    print(f\"Train metrics on epoch {epoch}: {train_dice_metric.item():.4f}, {train_iou_metric.item():.4f}\")\n    \n    train_dice.eval(), train_iou.eval()\n    evaluate(model)\n    print(\"-------------------\")\n    if epoch % 10 == 9:\n        torch.save({\n            'epoch': epoch + 1,\n            'state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n        }, \"deeplab.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate output","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef mask2string(dir):\n    model.eval()\n    ## mask --> string\n    strings = []\n    ids = []\n    data_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n#         print(path)\n#         img = cv2.imread(path)[:,:,::-1]\n\n        img = data_transforms(Image.open(path)).unsqueeze(0).cuda()\n    \n        output = model(img)['out']\n        pred = output.argmax(dim=1).cpu().numpy()\n        \n        for mask in range(2):\n            ids.append(f'{id}_{mask}')\n            string = rle_encode_one_mask(pred==mask+1)\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MASK_DIR_PATH = '../input/bkai-neopolyp/bkai-igh-neopolyp/test/test' # change this to the path to your output mask folder\nmodel.eval()\nres = mask2string(MASK_DIR_PATH)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}